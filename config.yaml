# ============================================================
# config.yaml (runner-side hardening; workers untouched)
# - 前段フィルタ(Preflight)を train.py で実行するための設定を追加
# - 実行側(=training.*)に必要なキーのみを定義（未知キーは置かない）
# - モデル定義は従来どおり（workers を変更しない）
# ============================================================

# ---------- Preflight: 学習前の簡易フィルタ（train.py 内蔵） ----------
# RDKit 由来の失敗や極端な長さの系列を「理由付きで」落とします。
# 許容ドロップ率(max_drop_pct)を超えた場合は中止。レポートは {result_dir}/qc/ に出力。
preflight:
  enable: true
  max_length: 198          # トークン長の上限（input/targetの両方に適用）
  max_drop_pct: 5          # 許容ドロップ率(%)。厳格運用は 0 に設定
  check_files: true        # 入力パスの存在確認
  report_dir: ./qc         # 相対パスは result_dir 配下に解決されます

# ---------- Model: workers に渡すそのままの構成 ----------
model:
  modules:
    teacherforcer:
      type: TeacherForcer
      length_dim: 1

    masker:
      type: MaskMaker
      mask_token: 3         # ← 語彙の[MASK]トークンIDに合わせる。例では3

    enc_embedding:
      type: PositionalEmbedding
      embedding:
        type: torch.nn.Embedding
        num_embeddings: 400
        embedding_dim: 512
      max_len: 256
      dropout: 0.0

    encoder:
      type: TransformerEncoder
      layer:
        type: SelfAttentionLayer
        d_model: 512
        nhead: 8
        dropout: 0.1
      n_layer: 6

    pooler:
      type: MeanPooler

    latent2mu:
      type: MLP
      n_embd: 512

    latent2var:
      type: MLP
      n_embd: 512

    vae:
      type: VAE

    latent2dec:
      type: MLP
      n_embd: 512

    dec_embedding:
      type: PositionalEmbedding
      embedding:
        type: torch.nn.Embedding
        num_embeddings: 400
        embedding_dim: 512
      max_len: 256
      dropout: 0.0

    decoder:
      type: TransformerDecoder
      layer:
        type: SelfAttentionLayer
        d_model: 512
        nhead: 8
        dropout: 0.1
      n_layer: 6
      max_len: 256

    dec2proba:
      type: MLP
      n_embd: 512

    dec_supporter:
      type: GreedyDecoder
      start_token: 1
      end_token: 2


  use_modules:
    - teacherforcer
    - masker
    - enc_embedding
    - encoder
    - pooler
    - latent2mu
    - latent2var
    - vae
    - latent2dec
    - dec_embedding
    - decoder
    - dec2proba
    - dec_supporter

  init:
    type: default
  seed: 111

# ---------- Training: 実行側の全設定（train.py が参照） ----------
training:
  # 実行出力ディレクトリ（$TIMESTAMP のみ使用可）
  result_dir:
    dirname: "./result/$TIMESTAMP_AllPubchem"
    duplicate: "error"    # "error" | "overwrite" | "merge" | "ask"

  # ログ・進捗表示
  verbose:
    show_tqdm: true
    loglevel:
      stream: info        # 標準出力
      file: debug         # ファイル出力（{result_dir}/log.txt）

  # 実行デバイス・再現性（runner と model を分けて初期化）
  gpuid: 0
  detect_anomaly: false
  deterministic: false
  runner_seed: 111
  model_seed: 111

  # データローダ設定（workers を変更せず、そのまま渡す）
  data:
    train:
      type: bucket
      seed: 1
      bucket_dset: input
      batch_size: [128, 96, 64, 48, 32, 16]
      bins: [20, 40, 60, 80, 100, 120, 140, 160]
      add_lower_margin: true
      add_upper_margin: true
      datasets:
        dfs: {}
        datasets:
          input:
            type: string
            dim: 1
            dtype: long
            len_name: src_len
            padding_value: 0
            # ※手元のパスに合わせて変更してください
            path_list: "./data/AllPubchem_test_random.pkl"
          target:
            type: string
            dim: 1
            dtype: long
            len_name: tgt_len
            padding_value: 0
            # ※手元のパスに合わせて変更してください
            path_list: "./data/AllPubchem_test_canonical.pkl"
    vals:
      valid:
        type: bucket
        seed: 1
        bucket_dset: input
        batch_size: [128, 96, 64, 48, 32, 16]
        bins: [20, 40, 60, 80, 100, 120, 140, 160]
        add_lower_margin: true
        add_upper_margin: true
        datasets:
          dfs: {}
          datasets:
            input:
              type: string
              dim: 1
              dtype: long
              len_name: src_len
              padding_value: 0
              path_list: "./data/AllPubchem_test_random.pkl"
            target:
              type: string
              dim: 1
              dtype: long
              len_name: tgt_len
              padding_value: 0
              path_list: "./data/AllPubchem_test_canonical.pkl"

  # Optimizer / LR Scheduler
  optimizer:
    type: adamw
    lr: 0.001
    betas: [0.9, 0.999]
    eps: 1.0e-8
    weight_decay: 0.01

  # ※実際のスケジューラ適用は pre_hooks の scheduler_alarm で行います
  scheduler:
    type: warmup
    warmup: 800

  # Optimizer の適用頻度（ステップ単位）
  schedule:
    opt_freq: 1

  # 評価指標（name: config のマップ。train.py は dict を想定）
  metrics:
    perfect:
      type: perfect
    partial_teacher:
      type: partial_teacher
    partial_greedy:
      type: partial_greedy

  # Accumulators（必要ならそのまま）
  accumulators:
    - type: numpy
      name: latent
      save_dir: "./result_np/latent"
      fields: ["z", "mu", "var"]
    - type: numpy
      name: pred
      save_dir: "./result_np/pred"
      fields: ["y_pred", "y_true"]

  # Hooks（train.py 内で hook_type2class に登録済みの型のみ使用）
  pre_hooks:
    lr_scheduler:
      type: scheduler_alarm   # train.py 側の SchedulerAlarmHook を使用
      target: step
      every: 1
      scheduler:              # 上の training.scheduler をそのまま渡す
        type: warmup
        warmup: 800

  post_hooks:
    validate:
      type: validation_alarm  # train.py 内で定義された ValidationAlarmHook
      target: step
      every: 1000
    checkpoint:
      type: checkpoint_alarm  # train.py 内で定義された CheckpointAlarm
      target: step
      every: 5000

  # ループ定義（workers のプロセスに合わせて従来どおり）
  train_loop:
    - op: "forward"
      inputs: ["src", "tgt"]
      outputs: ["logits"]
    - op: "loss"
      inputs: ["logits", "tgt"]
      outputs: ["loss"]
    - op: "backward"
      inputs: ["loss"]
    - op: "step"
    - op: "metrics"
      inputs: ["logits", "tgt"]
    - op: "accumulate"
      inputs: ["z", "mu", "var", "logits", "tgt"]

  val_loop:
    - op: "forward"
      inputs: ["src", "tgt"]
      outputs: ["logits"]
    - op: "metrics"
      inputs: ["logits", "tgt"]
    - op: "accumulate"
      inputs: ["z", "mu", "var", "logits", "tgt"]

  # 損失名（train.py が合算するキー）
  loss_names: ["loss"]

  # 補助設定
  val_loop_add_train: false
  abortion: { step: null, epoch: null, time: null }
  rstate: {}
  stocks: { score_df: "" }

  # 1 epoch あたりのステップ数（train.py 側で参照）
  steps_per_epoch: 1000


preflight:
  enable: true
  max_length: 198
  max_drop_pct: 5
  check_files: true
  report_dir: ./qc
  apply_to_train: true   # 既定 true
  apply_to_vals:  true   # ← ここを true にすれば、validation にも適用されます
